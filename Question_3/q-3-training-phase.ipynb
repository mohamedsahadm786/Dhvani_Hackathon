{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":11305158,"sourceType":"competition"},{"sourceId":1621957,"sourceType":"datasetVersion","datasetId":958550}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install ultralytics==8.*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T08:58:12.651863Z","iopub.execute_input":"2025-08-12T08:58:12.652300Z","iopub.status.idle":"2025-08-12T08:59:55.629459Z","shell.execute_reply.started":"2025-08-12T08:58:12.652266Z","shell.execute_reply":"2025-08-12T08:59:55.627970Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics==8.*\n  Downloading ultralytics-8.3.177-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (11.2.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (2.32.4)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.*) (2.2.3)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics==8.*)\n  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.*) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.*) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.*) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.*) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.*) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.*) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.*) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics==8.*) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics==8.*) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics==8.*) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics==8.*) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics==8.*) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics==8.*) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.*) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.*) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.*) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.*) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.*) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.*) (2025.6.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics==8.*)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.*) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.*) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.*) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.*) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics==8.*) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics==8.*) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics==8.*) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics==8.*) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics==8.*) (2024.2.0)\nDownloading ultralytics-8.3.177-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.177 ultralytics-thop-2.0.15\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ==== CLASS CENSUS: COUNT LABEL FREQUENCIES ACROSS ALL XMLs ====\nimport os, glob, xml.etree.ElementTree as ET\nfrom collections import Counter, defaultdict\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:30:01.281975Z","iopub.execute_input":"2025-08-12T09:30:01.282402Z","iopub.status.idle":"2025-08-12T09:30:01.544522Z","shell.execute_reply.started":"2025-08-12T09:30:01.282377Z","shell.execute_reply":"2025-08-12T09:30:01.543820Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ---- adjust this path to your dataset root ----\nSRC_TRAIN = \"/kaggle/input/vehicle-detection-dataset/test1/test\"\n\n# Find all XMLs (non-recursive if all files are flat; set recursive=True if nested)\nxml_files = sorted(glob.glob(os.path.join(SRC_TRAIN, \"*.xml\")))\nprint(f\"Found XML files: {len(xml_files)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:30:04.840244Z","iopub.execute_input":"2025-08-12T09:30:04.840597Z","iopub.status.idle":"2025-08-12T09:30:04.905285Z","shell.execute_reply.started":"2025-08-12T09:30:04.840575Z","shell.execute_reply":"2025-08-12T09:30:04.904741Z"}},"outputs":[{"name":"stdout","text":"Found XML files: 3003\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"instances = Counter()               # total bbox instances per class\nimages_per_class = defaultdict(set) # unique image ids containing the class\nparse_errors = []\n\nfor xp in xml_files:\n    try:\n        root = ET.parse(xp).getroot()\n    except Exception as e:\n        parse_errors.append((xp, str(e)))\n        continue\n\n    # Prefer <filename>, else fallback to XML filename stem\n    fname = (root.findtext(\"filename\") or \"\").strip()\n    image_id = os.path.splitext(os.path.basename(fname))[0] if fname else os.path.splitext(os.path.basename(xp))[0]\n\n    for obj in root.findall(\"object\"):\n        cls = (obj.findtext(\"name\") or \"\").strip().lower()\n        if not cls:\n            continue\n        instances[cls] += 1\n        images_per_class[cls].add(image_id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:30:07.785372Z","iopub.execute_input":"2025-08-12T09:30:07.785638Z","iopub.status.idle":"2025-08-12T09:30:30.792547Z","shell.execute_reply.started":"2025-08-12T09:30:07.785619Z","shell.execute_reply":"2025-08-12T09:30:30.791807Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Summarize\nrows = []\nfor cls, cnt in instances.items():\n    rows.append({\n        \"class\": cls,\n        \"instances\": cnt,\n        \"images\": len(images_per_class[cls])\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:30:36.228997Z","iopub.execute_input":"2025-08-12T09:30:36.229665Z","iopub.status.idle":"2025-08-12T09:30:36.233500Z","shell.execute_reply.started":"2025-08-12T09:30:36.229637Z","shell.execute_reply":"2025-08-12T09:30:36.232757Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = pd.DataFrame(rows).sort_values([\"instances\",\"images\"], ascending=False).reset_index(drop=True)\ndisplay(df.head(25))\nprint(f\"\\nUnique classes: {df.shape[0]}\")\nprint(f\"Total instances (all classes): {int(df['instances'].sum())}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:30:39.355829Z","iopub.execute_input":"2025-08-12T09:30:39.356368Z","iopub.status.idle":"2025-08-12T09:30:39.392248Z","shell.execute_reply.started":"2025-08-12T09:30:39.356343Z","shell.execute_reply":"2025-08-12T09:30:39.391469Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                   class  instances  images\n0                    car       5476    1621\n1               rickshaw       3549    1021\n2                    bus       3340    1558\n3   three wheelers (cng)       2990    1170\n4              motorbike       2284    1186\n5                  truck       1492     842\n6                 pickup       1225     792\n7                minivan        935     576\n8                    suv        860     539\n9                    van        756     449\n10               bicycle        459     352\n11         auto rickshaw        372     149\n12          human hauler        169     128\n13           wheelbarrow        120      93\n14               minibus         95      58\n15             ambulance         70      69\n16                  taxi         60      52\n17          army vehicle         43      39\n18               scooter         38      35\n19             policecar         32      30\n20            garbagevan          3       3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>instances</th>\n      <th>images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>car</td>\n      <td>5476</td>\n      <td>1621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rickshaw</td>\n      <td>3549</td>\n      <td>1021</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bus</td>\n      <td>3340</td>\n      <td>1558</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>three wheelers (cng)</td>\n      <td>2990</td>\n      <td>1170</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>motorbike</td>\n      <td>2284</td>\n      <td>1186</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>truck</td>\n      <td>1492</td>\n      <td>842</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>pickup</td>\n      <td>1225</td>\n      <td>792</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>minivan</td>\n      <td>935</td>\n      <td>576</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>suv</td>\n      <td>860</td>\n      <td>539</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>van</td>\n      <td>756</td>\n      <td>449</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>bicycle</td>\n      <td>459</td>\n      <td>352</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>auto rickshaw</td>\n      <td>372</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>human hauler</td>\n      <td>169</td>\n      <td>128</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>wheelbarrow</td>\n      <td>120</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>minibus</td>\n      <td>95</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ambulance</td>\n      <td>70</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>taxi</td>\n      <td>60</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>army vehicle</td>\n      <td>43</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>scooter</td>\n      <td>38</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>policecar</td>\n      <td>32</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>garbagevan</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nUnique classes: 21\nTotal instances (all classes): 24368\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Show a quick top-50 text summary\nprint(\"\\nTop classes (instances, images):\")\nfor cls, cnt in instances.most_common(50):\n    print(f\"{cls:28s}  inst={cnt:5d}  imgs={len(images_per_class[cls]):4d}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:30:52.556078Z","iopub.execute_input":"2025-08-12T09:30:52.556334Z","iopub.status.idle":"2025-08-12T09:30:52.561091Z","shell.execute_reply.started":"2025-08-12T09:30:52.556317Z","shell.execute_reply":"2025-08-12T09:30:52.560297Z"}},"outputs":[{"name":"stdout","text":"\nTop classes (instances, images):\ncar                           inst= 5476  imgs=1621\nrickshaw                      inst= 3549  imgs=1021\nbus                           inst= 3340  imgs=1558\nthree wheelers (cng)          inst= 2990  imgs=1170\nmotorbike                     inst= 2284  imgs=1186\ntruck                         inst= 1492  imgs= 842\npickup                        inst= 1225  imgs= 792\nminivan                       inst=  935  imgs= 576\nsuv                           inst=  860  imgs= 539\nvan                           inst=  756  imgs= 449\nbicycle                       inst=  459  imgs= 352\nauto rickshaw                 inst=  372  imgs= 149\nhuman hauler                  inst=  169  imgs= 128\nwheelbarrow                   inst=  120  imgs=  93\nminibus                       inst=   95  imgs=  58\nambulance                     inst=   70  imgs=  69\ntaxi                          inst=   60  imgs=  52\narmy vehicle                  inst=   43  imgs=  39\nscooter                       inst=   38  imgs=  35\npolicecar                     inst=   32  imgs=  30\ngarbagevan                    inst=    3  imgs=   3\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Optional: inspect any XML parse issues\nif parse_errors:\n    print(f\"\\nXML parse errors: {len(parse_errors)} (showing up to 5)\")\n    for p, e in parse_errors[:5]:\n        print(\" -\", os.path.basename(p), \"->\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:30:56.114343Z","iopub.execute_input":"2025-08-12T09:30:56.115030Z","iopub.status.idle":"2025-08-12T09:30:56.119498Z","shell.execute_reply.started":"2025-08-12T09:30:56.115005Z","shell.execute_reply":"2025-08-12T09:30:56.118854Z"}},"outputs":[{"name":"stdout","text":"\nXML parse errors: 1 (showing up to 5)\n - 231.xml -> syntax error: line 1, column 0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ----- OPTIONAL: canonicalized counts (uncomment and edit the map) -----\nCANON_MAP = {\n     \"minivan\": \"car\",\n     \"policecar\" : \"car\",\n     \"three wheelers (cng)\": \"rickshaw\",\n     \"auto rickshaw\": \"rickshaw\",\n     \"scooter\": \"motorbike\",\n    \"suv\": \"car\"\n    \n }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:31:00.035553Z","iopub.execute_input":"2025-08-12T09:31:00.036172Z","iopub.status.idle":"2025-08-12T09:31:00.039773Z","shell.execute_reply.started":"2025-08-12T09:31:00.036145Z","shell.execute_reply":"2025-08-12T09:31:00.039043Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"inst_canon = Counter()\nimgs_canon = defaultdict(set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:31:03.353378Z","iopub.execute_input":"2025-08-12T09:31:03.353635Z","iopub.status.idle":"2025-08-12T09:31:03.357308Z","shell.execute_reply.started":"2025-08-12T09:31:03.353615Z","shell.execute_reply":"2025-08-12T09:31:03.356741Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for cls, cnt in instances.items():\n    canon = CANON_MAP.get(cls, cls)\n    inst_canon[canon] += cnt\n    imgs_canon[canon] |= images_per_class[cls]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:31:08.250030Z","iopub.execute_input":"2025-08-12T09:31:08.250592Z","iopub.status.idle":"2025-08-12T09:31:08.255057Z","shell.execute_reply.started":"2025-08-12T09:31:08.250567Z","shell.execute_reply":"2025-08-12T09:31:08.254285Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"rows_c = [{\"class\": c, \"instances\": n, \"images\": len(imgs_canon[c])} for c, n in inst_canon.items()]\ndf_c = pd.DataFrame(rows_c).sort_values([\"instances\",\"images\"], ascending=False).reset_index(drop=True)\ndisplay(df_c.head(25))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:31:10.959233Z","iopub.execute_input":"2025-08-12T09:31:10.959961Z","iopub.status.idle":"2025-08-12T09:31:10.970966Z","shell.execute_reply.started":"2025-08-12T09:31:10.959937Z","shell.execute_reply":"2025-08-12T09:31:10.970338Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"           class  instances  images\n0            car      14606    1816\n1       rickshaw      13822    1751\n2            bus       6680    1558\n3      motorbike       4644    1196\n4          truck       2984     842\n5         pickup       2450     792\n6            van       1512     449\n7        bicycle        918     352\n8   human hauler        338     128\n9    wheelbarrow        240      93\n10       minibus        190      58\n11     ambulance        140      69\n12          taxi        120      52\n13  army vehicle         86      39\n14    garbagevan          6       3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>instances</th>\n      <th>images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>car</td>\n      <td>14606</td>\n      <td>1816</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rickshaw</td>\n      <td>13822</td>\n      <td>1751</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bus</td>\n      <td>6680</td>\n      <td>1558</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>motorbike</td>\n      <td>4644</td>\n      <td>1196</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>truck</td>\n      <td>2984</td>\n      <td>842</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>pickup</td>\n      <td>2450</td>\n      <td>792</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>van</td>\n      <td>1512</td>\n      <td>449</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bicycle</td>\n      <td>918</td>\n      <td>352</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>human hauler</td>\n      <td>338</td>\n      <td>128</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>wheelbarrow</td>\n      <td>240</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>minibus</td>\n      <td>190</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ambulance</td>\n      <td>140</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>taxi</td>\n      <td>120</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>army vehicle</td>\n      <td>86</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>garbagevan</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import importlib\n\npackage_name = \"iterstrat\"  # change this to the package you want to check\nspec = importlib.util.find_spec(package_name)\n\nif spec is not None:\n    print(f\"✅ '{package_name}' is installed.\")\nelse:\n    print(f\"❌ '{package_name}' is NOT installed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:56:31.831977Z","iopub.execute_input":"2025-08-12T09:56:31.832496Z","iopub.status.idle":"2025-08-12T09:56:31.837852Z","shell.execute_reply.started":"2025-08-12T09:56:31.832474Z","shell.execute_reply":"2025-08-12T09:56:31.837070Z"}},"outputs":[{"name":"stdout","text":"❌ 'iterstrat' is NOT installed.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import sys, subprocess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:04:51.078856Z","iopub.execute_input":"2025-08-12T10:04:51.079128Z","iopub.status.idle":"2025-08-12T10:04:51.083060Z","shell.execute_reply.started":"2025-08-12T10:04:51.079108Z","shell.execute_reply":"2025-08-12T10:04:51.082140Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def pip_install(pkg):\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-input\", pkg])\n        print(\"Installed:\", pkg)\n        return True\n    except Exception as e:\n        print(\"Failed:\", pkg, \"→\", e)\n        return False\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:05:48.688028Z","iopub.execute_input":"2025-08-12T10:05:48.688592Z","iopub.status.idle":"2025-08-12T10:05:48.692593Z","shell.execute_reply.started":"2025-08-12T10:05:48.688571Z","shell.execute_reply":"2025-08-12T10:05:48.692003Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Multi-label stratification (try options in order)\nok_iter = pip_install(\"iterative-stratification==0.1.7\")\nif not ok_iter:\n    ok_iter = pip_install(\"scikit-multilearn==0.2.0\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:06:13.591204Z","iopub.execute_input":"2025-08-12T10:06:13.591902Z","iopub.status.idle":"2025-08-12T10:06:16.865133Z","shell.execute_reply.started":"2025-08-12T10:06:13.591877Z","shell.execute_reply":"2025-08-12T10:06:16.864479Z"}},"outputs":[{"name":"stdout","text":"Installed: iterative-stratification==0.1.7\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# ---------------------------\n# 1) IMPORTS & CONFIG\n# ---------------------------\nimport os, glob, shutil, random, warnings, json\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nimport numpy as np\nfrom PIL import Image\nimport xml.etree.ElementTree as ET\nwarnings.filterwarnings(\"ignore\")\n\n# lxml (robust XML parser) – optional\ntry:\n    from lxml import etree as LET\n    HAS_LXML = True\nexcept Exception:\n    HAS_LXML = False\n\n# iterative stratification or fallbacks\nSPLITTER = None\ntry:\n    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n    SPLITTER = \"iterstrat\"\n    print(\"Using: iterative-stratification\")\nexcept Exception:\n    try:\n        from skmultilearn.model_selection import IterativeStratification\n        SPLITTER = \"skmultilearn\"\n        print(\"Using: scikit-multilearn IterativeStratification\")\n    except Exception:\n        SPLITTER = \"fallback\"\n        print(\"Using: simple fallback multilabel split\")\n\nfrom tqdm import tqdm\nfrom ultralytics import YOLO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:09:16.049563Z","iopub.execute_input":"2025-08-12T10:09:16.050102Z","iopub.status.idle":"2025-08-12T10:09:19.618470Z","shell.execute_reply.started":"2025-08-12T10:09:16.050074Z","shell.execute_reply":"2025-08-12T10:09:19.617880Z"}},"outputs":[{"name":"stdout","text":"Using: iterative-stratification\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# pip_install(\"ultralytics==8.*\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:07:38.331813Z","iopub.execute_input":"2025-08-12T10:07:38.332457Z","iopub.status.idle":"2025-08-12T10:08:47.788010Z","shell.execute_reply.started":"2025-08-12T10:07:38.332435Z","shell.execute_reply":"2025-08-12T10:08:47.787167Z"}},"outputs":[{"name":"stdout","text":"   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 16.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 4.7 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 96.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 79.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 38.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 2.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 7.8 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 30.8 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 9.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 8.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 83.8 MB/s eta 0:00:00\nInstalled: ultralytics==8.*\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"SEED = 42\nrandom.seed(SEED); np.random.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:10:36.781331Z","iopub.execute_input":"2025-08-12T10:10:36.782043Z","iopub.status.idle":"2025-08-12T10:10:36.785622Z","shell.execute_reply.started":"2025-08-12T10:10:36.782019Z","shell.execute_reply":"2025-08-12T10:10:36.784859Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# ---- paths (edit as needed) ----\nSRC_TRAIN = \"/kaggle/input/vehicle-detection-dataset/train/Final Train Dataset\"\nSRC_TEST  = \"/kaggle/input/vehicle-detection-dataset/test/Final Test Dataset\"  # if not present, it's fine\nWORKDIR   = \"/kaggle/working/vehdet\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:10:58.207078Z","iopub.execute_input":"2025-08-12T10:10:58.207352Z","iopub.status.idle":"2025-08-12T10:10:58.211121Z","shell.execute_reply.started":"2025-08-12T10:10:58.207332Z","shell.execute_reply":"2025-08-12T10:10:58.210422Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"\n# ---- experiment settings ----\nVAL_RATIO        = 0.15            # 0.10 for 90/10\nTARGET_CLASSES   = [\"car\",\"rickshaw\",\"bus\",\"motorbike\"]\nOVERSAMPLE_CLASS = \"motorbike\"\nOVERSAMPLE_FACTOR= 2               # 2x; set 3 if needed\nIMG_SIZE_PREF    = 1024            # accuracy-first; auto-fallback to 896 if OOM\nMODEL_WEIGHTS    = \"yolov8m.pt\"    # try 'yolov8l.pt' if VRAM allows\n\n# ---- canonicalization map (extend if you want) ----\nCANON_MAP = {\n    \"minivan\": \"car\",\n    \"policecar\": \"car\",\n    \"suv\": \"car\",\n    \"three wheelers (cng)\": \"rickshaw\",\n    \"auto rickshaw\": \"rickshaw\",\n    \"scooter\": \"motorbike\",\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:11:25.607364Z","iopub.execute_input":"2025-08-12T10:11:25.607935Z","iopub.status.idle":"2025-08-12T10:11:25.612008Z","shell.execute_reply.started":"2025-08-12T10:11:25.607912Z","shell.execute_reply":"2025-08-12T10:11:25.611245Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# skip known-bad XMLs\nSKIP_XML_BASENAMES = {\"231\"}   # stems without extension","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:11:38.342814Z","iopub.execute_input":"2025-08-12T10:11:38.343085Z","iopub.status.idle":"2025-08-12T10:11:38.346884Z","shell.execute_reply.started":"2025-08-12T10:11:38.343069Z","shell.execute_reply":"2025-08-12T10:11:38.346024Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# ---------------------------\n# 2) UTILS\n# ---------------------------\ndef ensure_dirs(base):\n    for p in [\n        base,\n        f\"{base}/images/train\", f\"{base}/labels/train\",\n        f\"{base}/images/val\",   f\"{base}/labels/val\",\n        f\"{base}/images/full_train\", f\"{base}/labels/full_train\",\n        f\"{base}/preds_test\"\n    ]:\n        Path(p).mkdir(parents=True, exist_ok=True)\n\ndef parse_xml_any(xml_path):\n    try:\n        if HAS_LXML:\n            return LET.parse(xml_path).getroot()\n        return ET.parse(xml_path).getroot()\n    except Exception:\n        return None\n\ndef get_img_size(path):\n    try:\n        with Image.open(path) as im:\n            return im.size  # (w,h)\n    except Exception:\n        return None, None\n\ndef voc_to_yolo(xmin,ymin,xmax,ymax,w,h):\n    # clip to image and normalize\n    xmin = max(0, min(xmin, w-1)); xmax = max(0, min(xmax, w-1))\n    ymin = max(0, min(ymin, h-1)); ymax = max(0, min(ymax, h-1))\n    bw = xmax - xmin; bh = ymax - ymin\n    if bw <= 1 or bh <= 1: return None\n    x_c = xmin + bw/2; y_c = ymin + bh/2\n    return x_c/w, y_c/h, bw/w, bh/h\n\ndef write_label_txt(path, items):\n    with open(path, \"w\") as f:\n        for (cid, x,y,w,h) in items:\n            f.write(f\"{cid} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n\ndef copy_and_label(split_stems, img_by_stem, image_ann, img_out, lbl_out):\n    n_img = 0; n_box = 0\n    for s in tqdm(split_stems, desc=f\"Write {Path(img_out).name}\"):\n        src_img = img_by_stem.get(s)\n        if not src_img: \n            continue\n        shutil.copy2(src_img, os.path.join(img_out, Path(src_img).name))\n        write_label_txt(os.path.join(lbl_out, f\"{s}.txt\"), image_ann[s][\"items\"])\n        n_img += 1; n_box += len(image_ann[s][\"items\"])\n    return n_img, n_box\n\ndef stems_with_class(stems, image_ann, cname):\n    return [s for s in stems if cname in image_ann[s][\"present\"]]\n\ndef duplicate_images(stems_to_dup, factor, img_dir, lbl_dir, class_name=\"minority\"):\n    made = 0\n    for s in tqdm(stems_to_dup, desc=f\"Oversample {class_name} x{factor}\"):\n        for k in range(1, factor):  # original already exists\n            # locate copied image in out dir by stem\n            candidates = [p for p in glob.glob(os.path.join(img_dir, \"*\")) if Path(p).stem == s]\n            if not candidates: \n                continue\n            src_img = candidates[0]\n            ext = Path(src_img).suffix\n            src_lbl = os.path.join(lbl_dir, f\"{s}.txt\")\n            if not os.path.exists(src_lbl): \n                continue\n            new_stem = f\"{s}_dup{k}\"\n            shutil.copy2(src_img, os.path.join(img_dir, f\"{new_stem}{ext}\"))\n            shutil.copy2(src_lbl, os.path.join(lbl_dir, f\"{new_stem}.txt\"))\n            made += 1\n    return made\n\ndef simple_iterative_split(stems, Y, val_ratio=0.15, seed=42):\n    \"\"\"\n    Fallback multilabel split:\n    - take ~val_ratio positives per class into val,\n    - fill remainder randomly (includes negatives).\n    \"\"\"\n    rng = np.random.RandomState(seed)\n    N = len(stems)\n    target_val = max(1, int(round(N * val_ratio)))\n    idx_all = np.arange(N)\n\n    val_idx_set = set()\n    for c in range(Y.shape[1]):\n        pos = np.where(Y[:, c] == 1)[0]\n        if len(pos) == 0: \n            continue\n        k = max(1, int(round(len(pos) * val_ratio)))\n        rng.shuffle(pos)\n        val_idx_set.update(pos[:k])\n\n    remaining = [i for i in idx_all if i not in val_idx_set]\n    rng.shuffle(remaining)\n    need = target_val - len(val_idx_set)\n    if need > 0:\n        val_idx_set.update(remaining[:need])\n\n    val_idx = np.array(sorted(val_idx_set))\n    train_idx = np.array([i for i in idx_all if i not in val_idx_set])\n    return train_idx, val_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:12:35.963273Z","iopub.execute_input":"2025-08-12T10:12:35.963550Z","iopub.status.idle":"2025-08-12T10:12:35.978909Z","shell.execute_reply.started":"2025-08-12T10:12:35.963528Z","shell.execute_reply":"2025-08-12T10:12:35.978147Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# ---------------------------\n# 3) PREP WORKDIR & DISCOVER FILES\n# ---------------------------\nensure_dirs(WORKDIR)\n\nxml_files = sorted(glob.glob(os.path.join(SRC_TRAIN, \"*.xml\")))\nimg_files = []\nfor ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.JPEG\",\"*.PNG\"):\n    img_files += glob.glob(os.path.join(SRC_TRAIN, ext))\n\nprint(f\"Found: {len(img_files)} images, {len(xml_files)} xmls\")\nimg_by_stem = {Path(p).stem: p for p in img_files}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:12:54.366371Z","iopub.execute_input":"2025-08-12T10:12:54.366947Z","iopub.status.idle":"2025-08-12T10:12:54.427084Z","shell.execute_reply.started":"2025-08-12T10:12:54.366923Z","shell.execute_reply":"2025-08-12T10:12:54.426339Z"}},"outputs":[{"name":"stdout","text":"Found: 3003 images, 3003 xmls\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# ---------------------------\n# 4) PARSE VOC → MEMORY (canonicalize + keep 4 classes)\n# ---------------------------\ncls2id = {c:i for i,c in enumerate(TARGET_CLASSES)}\nimage_ann = {}   # stem -> {\"w\":w,\"h\":h,\"items\":[(cid,x,y,w,h)], \"present\": set()}\nbad_xml = []\n\nfor xp in tqdm(xml_files, desc=\"Parsing XML\"):\n    stem = Path(xp).stem\n    if stem in SKIP_XML_BASENAMES:\n        bad_xml.append((xp, \"listed_skip\"))\n        continue\n\n    root = parse_xml_any(xp)\n    if root is None:\n        bad_xml.append((xp, \"parse_error\"))\n        continue\n\n    fname = (root.findtext(\"filename\") or \"\").strip()\n    img_stem = Path(fname).stem if fname else stem\n    img_path = img_by_stem.get(img_stem) or img_by_stem.get(stem)\n    if not img_path:\n        bad_xml.append((xp, \"missing_image\"))\n        continue\n\n    w = root.findtext(\"size/width\"); h = root.findtext(\"size/height\")\n    try:\n        w = int(w) if w else None; h = int(h) if h else None\n    except Exception:\n        w, h = None, None\n    if not w or not h:\n        w, h = get_img_size(img_path)\n        if not w or not h:\n            bad_xml.append((xp, \"no_size\"))\n            continue\n\n    rec = image_ann.get(img_stem, {\"w\":w, \"h\":h, \"items\":[], \"present\":set()})\n    for obj in root.findall(\"object\"):\n        name = (obj.findtext(\"name\") or \"\").strip().lower()\n        name = CANON_MAP.get(name, name)   # canonicalize\n        if name not in cls2id:\n            continue\n        bb = obj.find(\"bndbox\")\n        if bb is None: \n            continue\n        try:\n            xmin = float(bb.findtext(\"xmin\")); ymin = float(bb.findtext(\"ymin\"))\n            xmax = float(bb.findtext(\"xmax\")); ymax = float(bb.findtext(\"ymax\"))\n        except Exception:\n            continue\n        yline = voc_to_yolo(xmin,ymin,xmax,ymax,w,h)\n        if yline is None:\n            continue\n        rec[\"items\"].append((cls2id[name], *yline))\n        rec[\"present\"].add(name)\n\n    image_ann[img_stem] = rec\n\n# include negatives (images with no target-class labels)\nfor stem, p in img_by_stem.items():\n    if stem not in image_ann:\n        image_ann[stem] = {\"w\":None,\"h\":None,\"items\":[], \"present\":set()}\n\nprint(f\"Usable images: {len(image_ann)} | Skipped XMLs: {len(bad_xml)}\")\nif bad_xml:\n    print(\"Examples of skipped:\", bad_xml[:3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:17:35.908892Z","iopub.execute_input":"2025-08-12T10:17:35.909546Z","iopub.status.idle":"2025-08-12T10:17:42.572563Z","shell.execute_reply.started":"2025-08-12T10:17:35.909519Z","shell.execute_reply":"2025-08-12T10:17:42.571834Z"}},"outputs":[{"name":"stderr","text":"Parsing XML: 100%|██████████| 3003/3003 [00:06<00:00, 451.68it/s]","output_type":"stream"},{"name":"stdout","text":"Usable images: 3263 | Skipped XMLs: 1\nExamples of skipped: [('/kaggle/input/vehicle-detection-dataset/train/Final Train Dataset/231.xml', 'listed_skip')]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# ---------------------------\n# 5) MULTILABEL STRATIFIED SPLIT (with fallbacks)\n# ---------------------------\nstems = sorted(image_ann.keys())\nY = np.zeros((len(stems), len(TARGET_CLASSES)), dtype=int)\nfor i, s in enumerate(stems):\n    for c in image_ann[s][\"present\"]:\n        Y[i, cls2id[c]] = 1\n\nif SPLITTER == \"iterstrat\":\n    n_splits = max(2, int(round(1/VAL_RATIO)))\n    mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n    train_idx, val_idx = next(mskf.split(stems, Y))\nelif SPLITTER == \"skmultilearn\":\n    n_splits = max(2, int(round(1/VAL_RATIO)))\n    istrat = IterativeStratification(n_splits=n_splits, order=1)\n    # scikit-multilearn's split API differs; take first split\n    splits = list(istrat.split(np.zeros((len(stems),1)), Y))\n    train_idx, val_idx = splits[0]\nelse:\n    train_idx, val_idx = simple_iterative_split(stems, Y, val_ratio=VAL_RATIO, seed=SEED)\n\ntrain_stems = [stems[i] for i in train_idx]\nval_stems   = [stems[i] for i in val_idx]\nprint(f\"Split → train: {len(train_stems)} | val: {len(val_stems)} (≈ {len(val_stems)/len(stems):.2f} val)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:19:19.898910Z","iopub.execute_input":"2025-08-12T10:19:19.899227Z","iopub.status.idle":"2025-08-12T10:19:20.007355Z","shell.execute_reply.started":"2025-08-12T10:19:19.899203Z","shell.execute_reply":"2025-08-12T10:19:20.006749Z"}},"outputs":[{"name":"stdout","text":"Split → train: 2797 | val: 466 (≈ 0.14 val)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"\n# quick class presence report\ndef presence_counts(split_stems):\n    cnt = Counter()\n    for s in split_stems:\n        for c in image_ann[s][\"present\"]:\n            cnt[c] += 1\n    return cnt\n\nprint(\"Train presence:\", presence_counts(train_stems))\nprint(\"Val presence:  \", presence_counts(val_stems))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:21:11.728669Z","iopub.execute_input":"2025-08-12T10:21:11.729054Z","iopub.status.idle":"2025-08-12T10:21:11.737474Z","shell.execute_reply.started":"2025-08-12T10:21:11.729031Z","shell.execute_reply":"2025-08-12T10:21:11.736527Z"}},"outputs":[{"name":"stdout","text":"Train presence: Counter({'car': 1556, 'rickshaw': 1500, 'bus': 1336, 'motorbike': 1025})\nVal presence:   Counter({'car': 260, 'rickshaw': 251, 'bus': 222, 'motorbike': 171})\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# ---------------------------\n# 6) WRITE YOLO FILES (train/val)\n# ---------------------------\ntr_img, tr_lbl = f\"{WORKDIR}/images/train\", f\"{WORKDIR}/labels/train\"\nvl_img, vl_lbl = f\"{WORKDIR}/images/val\",   f\"{WORKDIR}/labels/val\"\nPath(tr_img).mkdir(parents=True, exist_ok=True)\nPath(tr_lbl).mkdir(parents=True, exist_ok=True)\nPath(vl_img).mkdir(parents=True, exist_ok=True)\nPath(vl_lbl).mkdir(parents=True, exist_ok=True)\n\nntr, btr = copy_and_label(train_stems, img_by_stem, image_ann, tr_img, tr_lbl)\nnvl, bvl = copy_and_label(val_stems,   img_by_stem, image_ann, vl_img, vl_lbl)\nprint(f\"Train: {ntr} imgs / {btr} boxes | Val: {nvl} imgs / {bvl} boxes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:21:43.797713Z","iopub.execute_input":"2025-08-12T10:21:43.798434Z","iopub.status.idle":"2025-08-12T10:22:34.572316Z","shell.execute_reply.started":"2025-08-12T10:21:43.798401Z","shell.execute_reply":"2025-08-12T10:22:34.571405Z"}},"outputs":[{"name":"stderr","text":"Write train: 100%|██████████| 2797/2797 [00:43<00:00, 64.29it/s] \nWrite val: 100%|██████████| 466/466 [00:07<00:00, 64.24it/s]","output_type":"stream"},{"name":"stdout","text":"Train: 2579 imgs / 13596 boxes | Val: 424 imgs / 2118 boxes\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ---------------------------\n# 7) OVERSAMPLE MINORITY CLASS (motorbike)\n# ---------------------------\nminority_train = stems_with_class(train_stems, image_ann, OVERSAMPLE_CLASS)\nprint(f\"Minority '{OVERSAMPLE_CLASS}' train images: {len(minority_train)}\")\n\nif OVERSAMPLE_FACTOR > 1 and minority_train:\n    made = duplicate_images(minority_train, OVERSAMPLE_FACTOR, tr_img, tr_lbl, class_name=OVERSAMPLE_CLASS)\n    print(f\"Created {made} duplicates for '{OVERSAMPLE_CLASS}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:23:47.672922Z","iopub.execute_input":"2025-08-12T10:23:47.673492Z","iopub.status.idle":"2025-08-12T10:24:06.271626Z","shell.execute_reply.started":"2025-08-12T10:23:47.673463Z","shell.execute_reply":"2025-08-12T10:24:06.270758Z"}},"outputs":[{"name":"stdout","text":"Minority 'motorbike' train images: 1025\n","output_type":"stream"},{"name":"stderr","text":"Oversample motorbike x2: 100%|██████████| 1025/1025 [00:18<00:00, 55.15it/s]","output_type":"stream"},{"name":"stdout","text":"Created 887 duplicates for 'motorbike'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# ---------------------------\n# 8) data.yaml\n# ---------------------------\nyaml_path = f\"{WORKDIR}/data.yaml\"\nwith open(yaml_path, \"w\") as f:\n    f.write(f\"path: {WORKDIR}\\n\")\n    f.write(\"train: images/train\\n\")\n    f.write(\"val: images/val\\n\")\n    f.write(f\"names: {TARGET_CLASSES}\\n\")\nprint(\"data.yaml:\\n\", open(yaml_path).read())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:24:47.743331Z","iopub.execute_input":"2025-08-12T10:24:47.743585Z","iopub.status.idle":"2025-08-12T10:24:47.749538Z","shell.execute_reply.started":"2025-08-12T10:24:47.743567Z","shell.execute_reply":"2025-08-12T10:24:47.748738Z"}},"outputs":[{"name":"stdout","text":"data.yaml:\n path: /kaggle/working/vehdet\ntrain: images/train\nval: images/val\nnames: ['car', 'rickshaw', 'bus', 'motorbike']\n\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"\n# ---------------------------\n# 9) TRAIN YOLO — PHASE 1 (freeze) → PHASE 2 (unfreeze)\n# ---------------------------\ndef train_yolo(imgsz):\n    model = YOLO(MODEL_WEIGHTS)   # COCO-pretrained\n    # Warm-up with frozen backbone (stabilize transfer)\n    model.train(\n        data=yaml_path, imgsz=imgsz, epochs=10, batch=-1, device=0, workers=2,\n        cache=True, patience=20, freeze=10, cos_lr=True, amp=True,\n        project=WORKDIR, name=f\"y8_phase1_{imgsz}\"\n    )\n    # Continue training unfrozen\n    run = model.train(\n        data=yaml_path, imgsz=imgsz, epochs=100, batch=-1, device=0, workers=2,\n        cache=True, patience=20, freeze=0, cos_lr=True, amp=True,\n        project=WORKDIR, name=f\"y8_phase2_{imgsz}\", resume=True\n    )\n    return model, run\n\ntry:\n    model, run = train_yolo(IMG_SIZE_PREF)\n    IMG_SIZE_USED = IMG_SIZE_PREF\nexcept Exception as e:\n    print(\"Hit OOM/other at\", IMG_SIZE_PREF, \"→ fallback to 896. Err:\", e)\n    model, run = train_yolo(896)\n    IMG_SIZE_USED = 896\n\nprint(\"Training complete @\", IMG_SIZE_USED)\nruns_dir = os.path.join(WORKDIR, f\"y8_phase2_{IMG_SIZE_USED}\")\nprint(\"Results saved to:\", runs_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T10:48:17.619407Z","iopub.execute_input":"2025-08-12T10:48:17.620279Z","iopub.status.idle":"2025-08-12T11:49:55.595385Z","shell.execute_reply.started":"2025-08-12T10:48:17.620235Z","shell.execute_reply":"2025-08-12T11:49:55.593286Z"}},"outputs":[{"name":"stderr","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100%|██████████| 49.7M/49.7M [00:00<00:00, 107MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/vehdet/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=y8_phase1_1024, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/vehdet, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/vehdet/y8_phase1_1024, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n","output_type":"stream"},{"name":"stderr","text":"Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|██████████| 755k/755k [00:00<00:00, 17.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \nModel summary: 169 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\nFreezing layer 'model.0.conv.weight'\nFreezing layer 'model.0.bn.weight'\nFreezing layer 'model.0.bn.bias'\nFreezing layer 'model.1.conv.weight'\nFreezing layer 'model.1.bn.weight'\nFreezing layer 'model.1.bn.bias'\nFreezing layer 'model.2.cv1.conv.weight'\nFreezing layer 'model.2.cv1.bn.weight'\nFreezing layer 'model.2.cv1.bn.bias'\nFreezing layer 'model.2.cv2.conv.weight'\nFreezing layer 'model.2.cv2.bn.weight'\nFreezing layer 'model.2.cv2.bn.bias'\nFreezing layer 'model.2.m.0.cv1.conv.weight'\nFreezing layer 'model.2.m.0.cv1.bn.weight'\nFreezing layer 'model.2.m.0.cv1.bn.bias'\nFreezing layer 'model.2.m.0.cv2.conv.weight'\nFreezing layer 'model.2.m.0.cv2.bn.weight'\nFreezing layer 'model.2.m.0.cv2.bn.bias'\nFreezing layer 'model.2.m.1.cv1.conv.weight'\nFreezing layer 'model.2.m.1.cv1.bn.weight'\nFreezing layer 'model.2.m.1.cv1.bn.bias'\nFreezing layer 'model.2.m.1.cv2.conv.weight'\nFreezing layer 'model.2.m.1.cv2.bn.weight'\nFreezing layer 'model.2.m.1.cv2.bn.bias'\nFreezing layer 'model.3.conv.weight'\nFreezing layer 'model.3.bn.weight'\nFreezing layer 'model.3.bn.bias'\nFreezing layer 'model.4.cv1.conv.weight'\nFreezing layer 'model.4.cv1.bn.weight'\nFreezing layer 'model.4.cv1.bn.bias'\nFreezing layer 'model.4.cv2.conv.weight'\nFreezing layer 'model.4.cv2.bn.weight'\nFreezing layer 'model.4.cv2.bn.bias'\nFreezing layer 'model.4.m.0.cv1.conv.weight'\nFreezing layer 'model.4.m.0.cv1.bn.weight'\nFreezing layer 'model.4.m.0.cv1.bn.bias'\nFreezing layer 'model.4.m.0.cv2.conv.weight'\nFreezing layer 'model.4.m.0.cv2.bn.weight'\nFreezing layer 'model.4.m.0.cv2.bn.bias'\nFreezing layer 'model.4.m.1.cv1.conv.weight'\nFreezing layer 'model.4.m.1.cv1.bn.weight'\nFreezing layer 'model.4.m.1.cv1.bn.bias'\nFreezing layer 'model.4.m.1.cv2.conv.weight'\nFreezing layer 'model.4.m.1.cv2.bn.weight'\nFreezing layer 'model.4.m.1.cv2.bn.bias'\nFreezing layer 'model.4.m.2.cv1.conv.weight'\nFreezing layer 'model.4.m.2.cv1.bn.weight'\nFreezing layer 'model.4.m.2.cv1.bn.bias'\nFreezing layer 'model.4.m.2.cv2.conv.weight'\nFreezing layer 'model.4.m.2.cv2.bn.weight'\nFreezing layer 'model.4.m.2.cv2.bn.bias'\nFreezing layer 'model.4.m.3.cv1.conv.weight'\nFreezing layer 'model.4.m.3.cv1.bn.weight'\nFreezing layer 'model.4.m.3.cv1.bn.bias'\nFreezing layer 'model.4.m.3.cv2.conv.weight'\nFreezing layer 'model.4.m.3.cv2.bn.weight'\nFreezing layer 'model.4.m.3.cv2.bn.bias'\nFreezing layer 'model.5.conv.weight'\nFreezing layer 'model.5.bn.weight'\nFreezing layer 'model.5.bn.bias'\nFreezing layer 'model.6.cv1.conv.weight'\nFreezing layer 'model.6.cv1.bn.weight'\nFreezing layer 'model.6.cv1.bn.bias'\nFreezing layer 'model.6.cv2.conv.weight'\nFreezing layer 'model.6.cv2.bn.weight'\nFreezing layer 'model.6.cv2.bn.bias'\nFreezing layer 'model.6.m.0.cv1.conv.weight'\nFreezing layer 'model.6.m.0.cv1.bn.weight'\nFreezing layer 'model.6.m.0.cv1.bn.bias'\nFreezing layer 'model.6.m.0.cv2.conv.weight'\nFreezing layer 'model.6.m.0.cv2.bn.weight'\nFreezing layer 'model.6.m.0.cv2.bn.bias'\nFreezing layer 'model.6.m.1.cv1.conv.weight'\nFreezing layer 'model.6.m.1.cv1.bn.weight'\nFreezing layer 'model.6.m.1.cv1.bn.bias'\nFreezing layer 'model.6.m.1.cv2.conv.weight'\nFreezing layer 'model.6.m.1.cv2.bn.weight'\nFreezing layer 'model.6.m.1.cv2.bn.bias'\nFreezing layer 'model.6.m.2.cv1.conv.weight'\nFreezing layer 'model.6.m.2.cv1.bn.weight'\nFreezing layer 'model.6.m.2.cv1.bn.bias'\nFreezing layer 'model.6.m.2.cv2.conv.weight'\nFreezing layer 'model.6.m.2.cv2.bn.weight'\nFreezing layer 'model.6.m.2.cv2.bn.bias'\nFreezing layer 'model.6.m.3.cv1.conv.weight'\nFreezing layer 'model.6.m.3.cv1.bn.weight'\nFreezing layer 'model.6.m.3.cv1.bn.bias'\nFreezing layer 'model.6.m.3.cv2.conv.weight'\nFreezing layer 'model.6.m.3.cv2.bn.weight'\nFreezing layer 'model.6.m.3.cv2.bn.bias'\nFreezing layer 'model.7.conv.weight'\nFreezing layer 'model.7.bn.weight'\nFreezing layer 'model.7.bn.bias'\nFreezing layer 'model.8.cv1.conv.weight'\nFreezing layer 'model.8.cv1.bn.weight'\nFreezing layer 'model.8.cv1.bn.bias'\nFreezing layer 'model.8.cv2.conv.weight'\nFreezing layer 'model.8.cv2.bn.weight'\nFreezing layer 'model.8.cv2.bn.bias'\nFreezing layer 'model.8.m.0.cv1.conv.weight'\nFreezing layer 'model.8.m.0.cv1.bn.weight'\nFreezing layer 'model.8.m.0.cv1.bn.bias'\nFreezing layer 'model.8.m.0.cv2.conv.weight'\nFreezing layer 'model.8.m.0.cv2.bn.weight'\nFreezing layer 'model.8.m.0.cv2.bn.bias'\nFreezing layer 'model.8.m.1.cv1.conv.weight'\nFreezing layer 'model.8.m.1.cv1.bn.weight'\nFreezing layer 'model.8.m.1.cv1.bn.bias'\nFreezing layer 'model.8.m.1.cv2.conv.weight'\nFreezing layer 'model.8.m.1.cv2.bn.weight'\nFreezing layer 'model.8.m.1.cv2.bn.bias'\nFreezing layer 'model.9.cv1.conv.weight'\nFreezing layer 'model.9.cv1.bn.weight'\nFreezing layer 'model.9.cv1.bn.bias'\nFreezing layer 'model.9.cv2.conv.weight'\nFreezing layer 'model.9.cv2.bn.weight'\nFreezing layer 'model.9.cv2.bn.bias'\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","output_type":"stream"},{"name":"stderr","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|██████████| 5.35M/5.35M [00:00<00:00, 67.2MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2182.4±900.9 MB/s, size: 211.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:09<00:00, 355.27it/s] ","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/vehdet/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=1024 at 60.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.26G reserved, 0.25G allocated, 15.38G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    25858636       202.4         4.383         47.76         143.9      (1, 3, 1024, 1024)                    list\n    25858636       404.9         4.998         61.72         108.9      (2, 3, 1024, 1024)                    list\n    25858636       809.7         6.115         116.9         134.4      (4, 3, 1024, 1024)                    list\n    25858636        1619         8.277         230.4           222      (8, 3, 1024, 1024)                    list\n    25858636        3239        17.929         413.9         588.1     (16, 3, 1024, 1024)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 9 for CUDA:0 9.35G/15.89G (59%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2926.1±1437.7 MB/s, size: 656.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (5.9GB RAM): 100%|██████████| 3466/3466 [00:31<00:00, 110.08it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 867.5±806.4 MB/s, size: 648.5 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehdet/labels/val... 424 images, 59 backgrounds, 0 corrupt: 100%|██████████| 424/424 [00:01<00:00, 270.56it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/145.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/153.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/159.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/169.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/170.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/182.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/187.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/Dipto_366.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/vehdet/labels/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB RAM): 100%|██████████| 424/424 [00:04<00:00, 105.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to /kaggle/working/vehdet/y8_phase1_1024/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0004921875), 83 bias(decay=0.0)\nImage sizes 1024 train, 1024 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/vehdet/y8_phase1_1024\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/10      6.43G      1.257       1.79      1.233          7       1024: 100%|██████████| 386/386 [03:20<00:00,  1.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.24it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.585      0.618      0.616      0.377\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/10      6.44G      1.266      1.259      1.258          4       1024: 100%|██████████| 386/386 [03:17<00:00,  1.96it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.47it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118       0.64      0.617      0.644      0.392\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/10      6.48G      1.241      1.158      1.246          6       1024: 100%|██████████| 386/386 [03:16<00:00,  1.96it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.642      0.642      0.669      0.416\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/10      6.53G      1.189       1.06      1.206          2       1024: 100%|██████████| 386/386 [03:16<00:00,  1.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.662      0.677      0.687      0.438\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/10      6.58G      1.141     0.9628      1.183          8       1024: 100%|██████████| 386/386 [03:16<00:00,  1.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.729      0.658      0.717      0.458\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/10      6.63G      1.083     0.8888       1.14         10       1024: 100%|██████████| 386/386 [03:16<00:00,  1.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.716      0.683      0.734      0.481\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/10      6.68G       1.05     0.8279      1.125          1       1024: 100%|██████████| 386/386 [03:16<00:00,  1.96it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.756      0.676       0.76      0.504\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/10      6.72G     0.9947     0.7515      1.088          0       1024: 100%|██████████| 386/386 [03:16<00:00,  1.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.731      0.726      0.775       0.52\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/10      6.77G     0.9564      0.702      1.068          1       1024: 100%|██████████| 386/386 [03:16<00:00,  1.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.738      0.725      0.782       0.53\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/10      6.82G     0.9367     0.6639      1.055          0       1024: 100%|██████████| 386/386 [03:16<00:00,  1.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.50it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.745      0.741       0.79      0.536\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n10 epochs completed in 0.577 hours.\nOptimizer stripped from /kaggle/working/vehdet/y8_phase1_1024/weights/last.pt, 52.1MB\nOptimizer stripped from /kaggle/working/vehdet/y8_phase1_1024/weights/best.pt, 52.1MB\n\nValidating /kaggle/working/vehdet/y8_phase1_1024/weights/best.pt...\nUltralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 92 layers, 25,842,076 parameters, 0 gradients, 78.7 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.746      0.741       0.79      0.537\n                   car        234        712      0.765      0.778      0.832      0.601\n              rickshaw        218        749      0.735      0.746      0.764      0.527\n                   bus        198        370      0.745      0.751      0.818      0.605\n             motorbike        148        287      0.737      0.686      0.744      0.413\nSpeed: 0.3ms preprocess, 19.4ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/vehdet/y8_phase1_1024\u001b[0m\nUltralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.001, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, crop_fraction=1.0, cutmix=0.0, data=/kaggle/working/vehdet/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=False, dynamic=False, embed=None, epochs=500, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, label_smoothing=0.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m, nbs=64, nms=False, opset=17, optimize=False, optimizer=SGD, overlap_mask=True, patience=50, perspective=0.0, plots=False, pose=12.0, pretrained=False, profile=False, project=YOLOv8, rect=False, resume=yolov8m.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=YOLOv8/yolov8m, save_frames=False, save_hybrid=False, save_json=False, save_period=-1, save_txt=False, scale=0.9, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=False, single_cls=False, source=ultralytics/assets/, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=4\nOverriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \nModel summary: 169 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2177.2±787.0 MB/s, size: 211.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=1024 at 60.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 1.38G reserved, 0.23G allocated, 14.28G free\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    25858636       202.4         5.205         37.17         179.6      (1, 3, 1024, 1024)                    list\n    25858636       404.9         6.468         63.33         260.2      (2, 3, 1024, 1024)                    list\n    25858636       809.7         8.672         118.6         347.1      (4, 3, 1024, 1024)                    list\n    25858636        1619        12.973         234.2         563.3      (8, 3, 1024, 1024)                    list\n    25858636        3239        19.139           428          1004     (16, 3, 1024, 1024)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 4 for CUDA:0 10.21G/15.89G (64%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2258.5±1055.9 MB/s, size: 656.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0m38.4GB disk space required, with 50% safety margin but only 17.3/19.5GB free, not caching images to disk\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1013.9±1061.5 MB/s, size: 648.5 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehdet/labels/val.cache... 424 images, 59 backgrounds, 0 corrupt: 100%|██████████| 424/424 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/145.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/153.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/159.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/169.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/170.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/182.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/187.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/Dipto_366.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.7GB Disk): 100%|██████████| 424/424 [00:04<00:00, 93.71it/s] \n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ 'label_smoothing' is deprecated and will be removed in in the future.\nWARNING ⚠️ 'crop_fraction' is deprecated and will be removed in in the future.\nWARNING ⚠️ 'save_hybrid' is deprecated and will be removed in in the future.\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.001), 83 bias(decay=0.0)\nHit OOM/other at 1024 → fallback to 896. Err: yolov8m.pt training to 500 epochs is finished, nothing to resume.\nStart a new training without resuming, i.e. 'yolo train model=yolov8m.pt'\nUltralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/vehdet/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=896, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=y8_phase1_896, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/vehdet, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/vehdet/y8_phase1_896, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\nOverriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \nModel summary: 169 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\nFreezing layer 'model.0.conv.weight'\nFreezing layer 'model.0.bn.weight'\nFreezing layer 'model.0.bn.bias'\nFreezing layer 'model.1.conv.weight'\nFreezing layer 'model.1.bn.weight'\nFreezing layer 'model.1.bn.bias'\nFreezing layer 'model.2.cv1.conv.weight'\nFreezing layer 'model.2.cv1.bn.weight'\nFreezing layer 'model.2.cv1.bn.bias'\nFreezing layer 'model.2.cv2.conv.weight'\nFreezing layer 'model.2.cv2.bn.weight'\nFreezing layer 'model.2.cv2.bn.bias'\nFreezing layer 'model.2.m.0.cv1.conv.weight'\nFreezing layer 'model.2.m.0.cv1.bn.weight'\nFreezing layer 'model.2.m.0.cv1.bn.bias'\nFreezing layer 'model.2.m.0.cv2.conv.weight'\nFreezing layer 'model.2.m.0.cv2.bn.weight'\nFreezing layer 'model.2.m.0.cv2.bn.bias'\nFreezing layer 'model.2.m.1.cv1.conv.weight'\nFreezing layer 'model.2.m.1.cv1.bn.weight'\nFreezing layer 'model.2.m.1.cv1.bn.bias'\nFreezing layer 'model.2.m.1.cv2.conv.weight'\nFreezing layer 'model.2.m.1.cv2.bn.weight'\nFreezing layer 'model.2.m.1.cv2.bn.bias'\nFreezing layer 'model.3.conv.weight'\nFreezing layer 'model.3.bn.weight'\nFreezing layer 'model.3.bn.bias'\nFreezing layer 'model.4.cv1.conv.weight'\nFreezing layer 'model.4.cv1.bn.weight'\nFreezing layer 'model.4.cv1.bn.bias'\nFreezing layer 'model.4.cv2.conv.weight'\nFreezing layer 'model.4.cv2.bn.weight'\nFreezing layer 'model.4.cv2.bn.bias'\nFreezing layer 'model.4.m.0.cv1.conv.weight'\nFreezing layer 'model.4.m.0.cv1.bn.weight'\nFreezing layer 'model.4.m.0.cv1.bn.bias'\nFreezing layer 'model.4.m.0.cv2.conv.weight'\nFreezing layer 'model.4.m.0.cv2.bn.weight'\nFreezing layer 'model.4.m.0.cv2.bn.bias'\nFreezing layer 'model.4.m.1.cv1.conv.weight'\nFreezing layer 'model.4.m.1.cv1.bn.weight'\nFreezing layer 'model.4.m.1.cv1.bn.bias'\nFreezing layer 'model.4.m.1.cv2.conv.weight'\nFreezing layer 'model.4.m.1.cv2.bn.weight'\nFreezing layer 'model.4.m.1.cv2.bn.bias'\nFreezing layer 'model.4.m.2.cv1.conv.weight'\nFreezing layer 'model.4.m.2.cv1.bn.weight'\nFreezing layer 'model.4.m.2.cv1.bn.bias'\nFreezing layer 'model.4.m.2.cv2.conv.weight'\nFreezing layer 'model.4.m.2.cv2.bn.weight'\nFreezing layer 'model.4.m.2.cv2.bn.bias'\nFreezing layer 'model.4.m.3.cv1.conv.weight'\nFreezing layer 'model.4.m.3.cv1.bn.weight'\nFreezing layer 'model.4.m.3.cv1.bn.bias'\nFreezing layer 'model.4.m.3.cv2.conv.weight'\nFreezing layer 'model.4.m.3.cv2.bn.weight'\nFreezing layer 'model.4.m.3.cv2.bn.bias'\nFreezing layer 'model.5.conv.weight'\nFreezing layer 'model.5.bn.weight'\nFreezing layer 'model.5.bn.bias'\nFreezing layer 'model.6.cv1.conv.weight'\nFreezing layer 'model.6.cv1.bn.weight'\nFreezing layer 'model.6.cv1.bn.bias'\nFreezing layer 'model.6.cv2.conv.weight'\nFreezing layer 'model.6.cv2.bn.weight'\nFreezing layer 'model.6.cv2.bn.bias'\nFreezing layer 'model.6.m.0.cv1.conv.weight'\nFreezing layer 'model.6.m.0.cv1.bn.weight'\nFreezing layer 'model.6.m.0.cv1.bn.bias'\nFreezing layer 'model.6.m.0.cv2.conv.weight'\nFreezing layer 'model.6.m.0.cv2.bn.weight'\nFreezing layer 'model.6.m.0.cv2.bn.bias'\nFreezing layer 'model.6.m.1.cv1.conv.weight'\nFreezing layer 'model.6.m.1.cv1.bn.weight'\nFreezing layer 'model.6.m.1.cv1.bn.bias'\nFreezing layer 'model.6.m.1.cv2.conv.weight'\nFreezing layer 'model.6.m.1.cv2.bn.weight'\nFreezing layer 'model.6.m.1.cv2.bn.bias'\nFreezing layer 'model.6.m.2.cv1.conv.weight'\nFreezing layer 'model.6.m.2.cv1.bn.weight'\nFreezing layer 'model.6.m.2.cv1.bn.bias'\nFreezing layer 'model.6.m.2.cv2.conv.weight'\nFreezing layer 'model.6.m.2.cv2.bn.weight'\nFreezing layer 'model.6.m.2.cv2.bn.bias'\nFreezing layer 'model.6.m.3.cv1.conv.weight'\nFreezing layer 'model.6.m.3.cv1.bn.weight'\nFreezing layer 'model.6.m.3.cv1.bn.bias'\nFreezing layer 'model.6.m.3.cv2.conv.weight'\nFreezing layer 'model.6.m.3.cv2.bn.weight'\nFreezing layer 'model.6.m.3.cv2.bn.bias'\nFreezing layer 'model.7.conv.weight'\nFreezing layer 'model.7.bn.weight'\nFreezing layer 'model.7.bn.bias'\nFreezing layer 'model.8.cv1.conv.weight'\nFreezing layer 'model.8.cv1.bn.weight'\nFreezing layer 'model.8.cv1.bn.bias'\nFreezing layer 'model.8.cv2.conv.weight'\nFreezing layer 'model.8.cv2.bn.weight'\nFreezing layer 'model.8.cv2.bn.bias'\nFreezing layer 'model.8.m.0.cv1.conv.weight'\nFreezing layer 'model.8.m.0.cv1.bn.weight'\nFreezing layer 'model.8.m.0.cv1.bn.bias'\nFreezing layer 'model.8.m.0.cv2.conv.weight'\nFreezing layer 'model.8.m.0.cv2.bn.weight'\nFreezing layer 'model.8.m.0.cv2.bn.bias'\nFreezing layer 'model.8.m.1.cv1.conv.weight'\nFreezing layer 'model.8.m.1.cv1.bn.weight'\nFreezing layer 'model.8.m.1.cv1.bn.bias'\nFreezing layer 'model.8.m.1.cv2.conv.weight'\nFreezing layer 'model.8.m.1.cv2.bn.weight'\nFreezing layer 'model.8.m.1.cv2.bn.bias'\nFreezing layer 'model.9.cv1.conv.weight'\nFreezing layer 'model.9.cv1.bn.weight'\nFreezing layer 'model.9.cv1.bn.bias'\nFreezing layer 'model.9.cv2.conv.weight'\nFreezing layer 'model.9.cv2.bn.weight'\nFreezing layer 'model.9.cv2.bn.bias'\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1883.2±833.3 MB/s, size: 211.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=896 at 60.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 1.21G reserved, 0.43G allocated, 14.25G free\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    25858636         155         2.636         38.17         53.81        (1, 3, 896, 896)                    list\n    25858636         310         3.058         50.28         68.98        (2, 3, 896, 896)                    list\n    25858636         620         4.058         92.07         91.37        (4, 3, 896, 896)                    list\n    25858636        1240         5.587         181.1         153.1        (8, 3, 896, 896)                    list\n    25858636        2480         9.599         322.3         267.9       (16, 3, 896, 896)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 14 for CUDA:0 10.23G/15.89G (64%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2756.7±1141.4 MB/s, size: 656.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.5GB RAM): 100%|██████████| 3466/3466 [00:35<00:00, 98.01it/s] ","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 557.9±224.0 MB/s, size: 648.5 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehdet/labels/val.cache... 424 images, 59 backgrounds, 0 corrupt: 100%|██████████| 424/424 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/145.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/153.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/159.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/169.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/170.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/182.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/187.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/Dipto_366.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB RAM): 100%|██████████| 424/424 [00:01<00:00, 216.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to /kaggle/working/vehdet/y8_phase1_896/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.000546875), 83 bias(decay=0.0)\nImage sizes 896 train, 896 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/vehdet/y8_phase1_896\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/10      5.17G      1.245      1.731      1.192         69        896: 100%|██████████| 248/248 [02:18<00:00,  1.79it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.30it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.598      0.557      0.561      0.337\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/10      6.93G      1.284      1.251      1.235         31        896: 100%|██████████| 248/248 [02:16<00:00,  1.81it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.34it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.627      0.645      0.638      0.392\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/10      6.96G      1.262      1.143      1.217         42        896: 100%|██████████| 248/248 [02:16<00:00,  1.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.34it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.702      0.608      0.672      0.416\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/10      6.96G      1.206       1.03      1.181         35        896: 100%|██████████| 248/248 [02:15<00:00,  1.83it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.695      0.629      0.698      0.436\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/10      6.96G      1.144     0.9509      1.158         50        896: 100%|██████████| 248/248 [02:15<00:00,  1.83it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.686      0.651      0.706      0.458\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/10      6.96G      1.092     0.8829      1.123         25        896: 100%|██████████| 248/248 [02:15<00:00,  1.83it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.32it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.738       0.67      0.722      0.471\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/10      6.96G      1.051     0.8096      1.098         33        896: 100%|██████████| 248/248 [02:16<00:00,  1.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.34it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.751      0.675      0.745      0.494\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/10      6.96G      1.007      0.748      1.078         34        896: 100%|██████████| 248/248 [02:15<00:00,  1.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.716      0.708      0.756      0.512\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/10      6.96G     0.9706     0.6972      1.055         27        896: 100%|██████████| 248/248 [02:15<00:00,  1.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.34it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.747      0.692      0.766      0.522\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/10      6.96G      0.947     0.6603      1.041        149        896: 100%|██████████| 248/248 [02:16<00:00,  1.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:06<00:00,  2.31it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.756      0.706      0.775      0.533\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n10 epochs completed in 0.400 hours.\nOptimizer stripped from /kaggle/working/vehdet/y8_phase1_896/weights/last.pt, 52.0MB\nOptimizer stripped from /kaggle/working/vehdet/y8_phase1_896/weights/best.pt, 52.0MB\n\nValidating /kaggle/working/vehdet/y8_phase1_896/weights/best.pt...\nUltralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 92 layers, 25,842,076 parameters, 0 gradients, 78.7 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.756      0.705      0.775      0.532\n                   car        234        712      0.782      0.763      0.821      0.588\n              rickshaw        218        749      0.752      0.704      0.763      0.532\n                   bus        198        370      0.759       0.75      0.825      0.618\n             motorbike        148        287      0.731      0.603      0.691      0.392\nSpeed: 0.2ms preprocess, 12.9ms inference, 0.0ms loss, 2.3ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/vehdet/y8_phase1_896\u001b[0m\nUltralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.001, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, crop_fraction=1.0, cutmix=0.0, data=/kaggle/working/vehdet/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=False, dynamic=False, embed=None, epochs=500, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=896, int8=False, iou=0.7, keras=False, kobj=1.0, label_smoothing=0.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m2, nbs=64, nms=False, opset=17, optimize=False, optimizer=SGD, overlap_mask=True, patience=50, perspective=0.0, plots=False, pose=12.0, pretrained=False, profile=False, project=YOLOv8, rect=False, resume=yolov8m.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=YOLOv8/yolov8m2, save_frames=False, save_hybrid=False, save_json=False, save_period=-1, save_txt=False, scale=0.9, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=False, single_cls=False, source=ultralytics/assets/, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=4\nOverriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \nModel summary: 169 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1935.8±621.0 MB/s, size: 211.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=896 at 60.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 1.51G reserved, 0.43G allocated, 13.95G free\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    25858636         155         3.238         39.83           111        (1, 3, 896, 896)                    list\n    25858636         310         4.255          52.6         172.7        (2, 3, 896, 896)                    list\n    25858636         620         5.992         94.91         239.1        (4, 3, 896, 896)                    list\n    25858636        1240         9.441         186.5         397.3        (8, 3, 896, 896)                    list\n    25858636        2480        16.316         333.2         686.5       (16, 3, 896, 896)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 6 for CUDA:0 9.65G/15.89G (61%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2031.0±838.4 MB/s, size: 656.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0m38.4GB disk space required, with 50% safety margin but only 14.5/19.5GB free, not caching images to disk\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 827.0±978.6 MB/s, size: 648.5 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehdet/labels/val.cache... 424 images, 59 backgrounds, 0 corrupt: 100%|██████████| 424/424 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/145.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/153.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/159.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/169.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/170.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/182.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/187.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/Dipto_366.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.7GB Disk): 100%|██████████| 424/424 [00:00<00:00, 41875.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ 'label_smoothing' is deprecated and will be removed in in the future.\nWARNING ⚠️ 'crop_fraction' is deprecated and will be removed in in the future.\nWARNING ⚠️ 'save_hybrid' is deprecated and will be removed in in the future.\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00103125), 83 bias(decay=0.0)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2349130060.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_yolo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE_PREF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mIMG_SIZE_USED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIMG_SIZE_PREF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2349130060.py\u001b[0m in \u001b[0;36mtrain_yolo\u001b[0;34m(imgsz)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Continue training unfrozen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     run = model.train(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# do not move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mresume_training\u001b[0;34m(self, ckpt)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"updates\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         assert start_epoch > 0, (\n\u001b[0m\u001b[1;32m    791\u001b[0m             \u001b[0;34mf\"{self.args.model} training to {self.epochs} epochs is finished, nothing to resume.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: yolov8m.pt training to 500 epochs is finished, nothing to resume.\nStart a new training without resuming, i.e. 'yolo train model=yolov8m.pt'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2349130060.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hit OOM/other at\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE_PREF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"→ fallback to 896. Err:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_yolo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m896\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mIMG_SIZE_USED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m896\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2349130060.py\u001b[0m in \u001b[0;36mtrain_yolo\u001b[0;34m(imgsz)\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Continue training unfrozen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     run = model.train(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# do not move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_pretrain_routine_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mresume_training\u001b[0;34m(self, ckpt)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ema\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# EMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"updates\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         assert start_epoch > 0, (\n\u001b[0m\u001b[1;32m    791\u001b[0m             \u001b[0;34mf\"{self.args.model} training to {self.epochs} epochs is finished, nothing to resume.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;34mf\"Start a new training without resuming, i.e. 'yolo train model={self.args.model}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: yolov8m.pt training to 500 epochs is finished, nothing to resume.\nStart a new training without resuming, i.e. 'yolo train model=yolov8m.pt'"],"ename":"AssertionError","evalue":"yolov8m.pt training to 500 epochs is finished, nothing to resume.\nStart a new training without resuming, i.e. 'yolo train model=yolov8m.pt'","output_type":"error"}],"execution_count":37},{"cell_type":"code","source":"WORKDIR = \"/kaggle/working/vehdet\"\n\ndef find_latest(prefix):\n    cands = sorted(glob.glob(os.path.join(WORKDIR, f\"{prefix}_*\")), key=os.path.getmtime, reverse=True)\n    return cands[0] if cands else None\n\np1_dir = find_latest(\"y8_phase1\")\np2_dir = find_latest(\"y8_phase2\")\n\nprint(\"Phase-1 run:\", p1_dir)\nprint(\"Phase-2 run:\", p2_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T12:48:57.445405Z","iopub.execute_input":"2025-08-12T12:48:57.445836Z","iopub.status.idle":"2025-08-12T12:48:57.453615Z","shell.execute_reply.started":"2025-08-12T12:48:57.445793Z","shell.execute_reply":"2025-08-12T12:48:57.452889Z"}},"outputs":[{"name":"stdout","text":"Phase-1 run: /kaggle/working/vehdet/y8_phase1_896\nPhase-2 run: None\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# ================= SAFEST PHASE-2 START/RESUME (robust Phase-1 finder + per-epoch saves) ================\nimport os, glob, time, json\nfrom pathlib import Path\nimport pandas as pd\nfrom ultralytics import YOLO\n\nWORKDIR = \"/kaggle/working/vehdet\"\nDATA_YAML = f\"{WORKDIR}/data.yaml\"\nTARGET_PHASE2_EPOCHS = 100\nFORCE_SAVE_PERIOD = 1  # save a checkpoint every epoch\n\ndef list_phase_dirs(prefix, roots):\n    \"\"\"Return candidate run dirs matching prefix under given roots, newest first.\"\"\"\n    cands = []\n    for root in roots:\n        for d in glob.glob(os.path.join(root, f\"{prefix}_*\")):\n            if os.path.isdir(d):\n                cands.append((d, os.path.getmtime(d)))\n    return [d for d,_ in sorted(cands, key=lambda x: x[1], reverse=True)]\n\ndef find_ckpt(run_dir):\n    \"\"\"Return (ckpt_path, type) where type in {'last','best'} if present, else (None,None).\"\"\"\n    for nm in (\"last.pt\",\"best.pt\"):\n        p = os.path.join(run_dir, \"weights\", nm)\n        if os.path.exists(p): return p, nm.split(\".\")[0]\n    return None, None\n\ndef find_phase1_ckpt():\n    \"\"\"Find a Phase-1 run that actually has weights, prefer newest with last.pt then best.pt.\"\"\"\n    # 1) Prefer RUNS under WORKDIR\n    for d in list_phase_dirs(\"y8_phase1\", [WORKDIR]):\n        ck, kind = find_ckpt(d)\n        if ck: return d, ck\n    # 2) Fallback: search anywhere under /kaggle/working\n    for d in list_phase_dirs(\"y8_phase1\", [\"/kaggle/working\"]):\n        ck, kind = find_ckpt(d)\n        if ck: return d, ck\n    return None, None\n\ndef find_phase2_dir():\n    \"\"\"Return newest Phase-2 dir (may or may not have weights).\"\"\"\n    dirs = list_phase_dirs(\"y8_phase2\", [WORKDIR])\n    return dirs[0] if dirs else None\n\ndef epochs_done(run_dir):\n    csv = os.path.join(run_dir, \"results.csv\")\n    if not os.path.exists(csv): return 0\n    try:\n        df = pd.read_csv(csv)\n        return (int(df[\"epoch\"].max()) + 1) if \"epoch\" in df.columns else len(df)\n    except Exception:\n        return 0\n\ndef get_imgsz_from_args(run_dir, default=None):\n    for name in (\"args.yaml\",\"args.json\"):\n        p = os.path.join(run_dir, name)\n        if os.path.exists(p):\n            try:\n                if p.endswith(\".yaml\"):\n                    with open(p,\"r\") as f:\n                        for line in f:\n                            if line.strip().startswith(\"imgsz:\"):\n                                return int(line.split(\":\",1)[1].strip())\n                else:\n                    with open(p,\"r\") as f:\n                        j = json.load(f)\n                        if \"imgsz\" in j: return int(j[\"imgsz\"])\n            except: pass\n    # fallback: parse suffix e.g. y8_phase1_896\n    try:\n        return int(Path(run_dir).name.split(\"_\")[-1])\n    except:\n        return default\n\n# -------- 1) Robust Phase-1 check (NO re-running Phase-1) --------\np1_dir, p1_ckpt = find_phase1_ckpt()\nassert p1_dir, \"❌ No Phase-1 run folder found under /kaggle/working. Please (re)train Phase-1 once.\"\nassert p1_ckpt and os.path.exists(p1_ckpt), f\"❌ Phase-1 run found but no weights file: {p1_dir}\"\nprint(f\"✅ Phase-1 OK → {p1_dir}\\n   Using checkpoint: {p1_ckpt}\")\n\nimgsz = get_imgsz_from_args(p1_dir, default=896)\n\n# -------- 2) Phase-2 start/continue with per-epoch saves --------\np2_dir = find_phase2_dir()\nif p2_dir:\n    done = epochs_done(p2_dir)\n    p2_ckpt, _ = find_ckpt(p2_dir)\n    print(f\"🔎 Phase-2 found → {p2_dir} | epochs logged: {done} | ckpt: {p2_ckpt}\")\n\n    remain = max(1, TARGET_PHASE2_EPOCHS - done)\n    # To enforce save_period=1 going forward, continue in a NEW run that we control:\n    if p2_ckpt:\n        new_name = f\"{Path(p2_dir).name}_cont_{int(time.time())}\"\n        print(f\"➡️  Continuing Phase-2 for {remain} epochs with per-epoch saving → {new_name} (imgsz={imgsz})\")\n        base = YOLO(\"yolov8m.pt\")  # arch placeholder; resume path loads your exact state\n        base.train(\n            data=DATA_YAML,\n            imgsz=imgsz,\n            epochs=remain,\n            batch=-1, device=0, workers=2,\n            cache=True,\n            patience=max(5, min(20, remain//2)),\n            freeze=0, cos_lr=True, amp=True,\n            deterministic=True,\n            project=os.path.dirname(p2_dir),\n            name=new_name,\n            resume=p2_ckpt,                 # resume from existing Phase-2 checkpoint\n            save=True,\n            save_period=FORCE_SAVE_PERIOD,  # save EVERY epoch\n            plots=True,\n        )\n        print(f\"✅ Continued run at: {os.path.join(os.path.dirname(p2_dir), new_name)}\")\n    else:\n        # No weights in the found Phase-2 dir (maybe a stub). Start fresh from Phase-1 weights.\n        target_name = f\"y8_phase2_{imgsz}\"\n        print(f\"ℹ️ Found Phase-2 folder without weights. Starting fresh from Phase-1 → {target_name}\")\n        model = YOLO(p1_ckpt)\n        model.train(\n            data=DATA_YAML,\n            imgsz=imgsz,\n            epochs=TARGET_PHASE2_EPOCHS,\n            batch=-1, device=0, workers=2,\n            cache=True,\n            patience=20,\n            freeze=0,\n            cos_lr=True, amp=True,\n            deterministic=True,\n            project=WORKDIR, name=target_name,\n            save=True,\n            save_period=FORCE_SAVE_PERIOD,\n            plots=True,\n        )\n        print(f\"✅ New Phase-2 run at: {os.path.join(WORKDIR, target_name)}\")\nelse:\n    # No Phase-2 yet → start it from Phase-1 weights\n    target_name = f\"y8_phase2_{imgsz}\"\n    print(f\"ℹ️ No Phase-2 run found. Starting Phase-2 from Phase-1 → {target_name} (imgsz={imgsz})\")\n    model = YOLO(p1_ckpt)\n    model.train(\n        data=DATA_YAML,\n        imgsz=imgsz,\n        epochs=TARGET_PHASE2_EPOCHS,\n        batch=-1, device=0, workers=2,\n        cache=True,\n        patience=20,\n        freeze=0,\n        cos_lr=True, amp=True,\n        deterministic=True,\n        project=WORKDIR, name=target_name,\n        save=True,\n        save_period=FORCE_SAVE_PERIOD,\n        plots=True,\n    )\n    print(f\"✅ New Phase-2 run at: {os.path.join(WORKDIR, target_name)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:26:16.296727Z","iopub.execute_input":"2025-08-12T13:26:16.297350Z"}},"outputs":[{"name":"stdout","text":"✅ Phase-1 OK → /kaggle/working/vehdet/y8_phase1_896\n   Using checkpoint: /kaggle/working/vehdet/y8_phase1_896/weights/last.pt\nℹ️ No Phase-2 run found. Starting Phase-2 from Phase-1 → y8_phase2_896 (imgsz=896)\nUltralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/vehdet/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=0, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=896, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/vehdet/y8_phase1_896/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=y8_phase2_896, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/vehdet, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/vehdet/y8_phase2_896, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \nModel summary: 169 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n\nTransferred 475/475 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1688.3±389.7 MB/s, size: 211.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=896 at 60.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 1.29G reserved, 0.73G allocated, 13.87G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"    25858636         155         2.867         41.95           120        (1, 3, 896, 896)                    list\n    25858636         310         3.930         51.15         173.1        (2, 3, 896, 896)                    list\n    25858636         620         5.675         94.62         239.3        (4, 3, 896, 896)                    list\n    25858636        1240         9.022           185         397.2        (8, 3, 896, 896)                    list\n    25858636        2480        15.899         338.3         686.5       (16, 3, 896, 896)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 6 for CUDA:0 9.35G/15.89G (59%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2132.8±980.1 MB/s, size: 656.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehdet/labels/train.cache... 3466 images, 379 backgrounds, 0 corrupt: 100%|██████████| 3466/3466 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/144.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/146.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/147.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/148.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/149.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/150.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/151.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/152.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/154.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/155.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/156.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/157.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/158.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/160.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/161.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/162.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/163.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/164.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/165.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/166.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/167.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/168.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/171.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/172.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/173.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/174.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/175.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/176.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/177.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/178.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/179.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/180.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/181.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/183.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/184.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/185.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/186.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/188.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/189.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/190.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/191.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/192.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_351.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_352_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_353_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_360_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_363_dup1.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vehdet/images/train/Dipto_364_dup1.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.5GB RAM): 100%|██████████| 3466/3466 [00:30<00:00, 113.76it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 412.5±121.2 MB/s, size: 648.5 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehdet/labels/val.cache... 424 images, 59 backgrounds, 0 corrupt: 100%|██████████| 424/424 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/145.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/153.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/159.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/169.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/170.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/182.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/187.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vehdet/images/val/Dipto_366.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB RAM): 100%|██████████| 424/424 [00:16<00:00, 25.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to /kaggle/working/vehdet/y8_phase2_896/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.000515625), 83 bias(decay=0.0)\nImage sizes 896 train, 896 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/vehdet/y8_phase2_896\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100      5.24G      1.126      1.012      1.146         30        896: 100%|██████████| 578/578 [04:43<00:00,  2.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.658      0.562      0.604      0.378\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100      5.24G      1.257      1.216      1.232         19        896: 100%|██████████| 578/578 [04:38<00:00,  2.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.619      0.527      0.538      0.324\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      5.24G      1.279      1.234      1.244         66        896: 100%|██████████| 578/578 [04:38<00:00,  2.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.657      0.579      0.619      0.387\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100      5.24G      1.241      1.154      1.219         55        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118        0.7       0.59      0.648      0.411\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      5.24G      1.208      1.102      1.205         43        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.698      0.589      0.662      0.423\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100      5.29G      1.178      1.042      1.184          9        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118       0.74      0.578       0.66      0.422\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100      6.03G      1.166          1      1.173         30        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.697      0.644      0.694      0.448\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      6.03G      1.144     0.9696      1.155         43        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118       0.69      0.661      0.698      0.447\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100       6.1G      1.109     0.9265       1.14         55        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.727      0.648      0.706      0.457\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100       6.1G        1.1     0.9122       1.14         84        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.718      0.656      0.712      0.462\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100      6.16G      1.088     0.8941      1.125        100        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.732      0.638      0.709      0.464\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100      6.16G      1.076      0.851      1.121         38        896: 100%|██████████| 578/578 [04:38<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.716      0.673      0.713      0.469\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100      6.16G      1.052     0.8299      1.108        181        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.735      0.671      0.735      0.483\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100      6.16G      1.038     0.8063      1.102         13        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.699      0.693      0.736      0.486\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100      6.16G      1.032     0.8129      1.097         43        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.722      0.696      0.737      0.489\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100      6.16G      1.017     0.7704      1.085         61        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.784       0.66      0.741      0.493\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/100      6.16G     0.9943      0.749      1.076         44        896: 100%|██████████| 578/578 [04:37<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        424       2118      0.755      0.674      0.738      0.488\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/100      6.16G      1.001     0.7459      1.076         73        896:  40%|███▉      | 229/578 [01:50<02:47,  2.08it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# ================== PHASE-2 STATUS + CHECKPOINT INTEGRITY ==================\nimport os, glob, json, time\nfrom pathlib import Path\nimport pandas as pd\n\nWORKDIR = \"/kaggle/working/vehdet\"\nCHECK_LOAD = True   # set False if you don't want to actually load weights (saves a bit of time)\n\ndef latest_phase2(root):\n    runs = glob.glob(os.path.join(root, \"y8_phase2_*\"))\n    if not runs: \n        return None\n    return sorted(runs, key=os.path.getmtime, reverse=True)[0]\n\ndef epochs_from_results_csv(run_dir):\n    csv = os.path.join(run_dir, \"results.csv\")\n    if not os.path.exists(csv):\n        return 0, None, None, None\n    try:\n        df = pd.read_csv(csv)\n        # completed epochs (CSV is 0-indexed)\n        done = int(df[\"epoch\"].max()) + 1 if \"epoch\" in df.columns else len(df)\n        # try to compute best epoch by fitness or mAP\n        best_epoch = None; best_col = None; best_val = None\n        for col in [\"fitness\", \"metrics/mAP50-95(B)\", \"metrics/mAP50(B)\", \"metrics/mAP50-95\", \"metrics/mAP50\"]:\n            if col in df.columns:\n                idx = int(df[col].idxmax())\n                best_epoch = int(df.loc[idx, \"epoch\"]) if \"epoch\" in df.columns else idx\n                best_col = col\n                best_val = float(df.loc[idx, col])\n                break\n        return done, best_epoch, best_col, best_val\n    except Exception as e:\n        print(\"⚠️ Could not parse results.csv:\", e)\n        return 0, None, None, None\n\ndef list_weights(run_dir):\n    wdir = os.path.join(run_dir, \"weights\")\n    ep_files = []\n    for p in glob.glob(os.path.join(wdir, \"epoch*.pt\")):\n        try:\n            n = int(Path(p).stem.replace(\"epoch\", \"\"))\n            ep_files.append((n, p))\n        except:\n            pass\n    ep_files.sort(key=lambda x: x[0])\n    best = os.path.join(wdir, \"best.pt\") if os.path.exists(os.path.join(wdir, \"best.pt\")) else None\n    last = os.path.join(wdir, \"last.pt\") if os.path.exists(os.path.join(wdir, \"last.pt\")) else None\n    return ep_files, best, last\n\ndef file_info(p):\n    try:\n        st = os.stat(p)\n        return f\"{Path(p).name}  |  {st.st_size/1e6:.1f} MB  |  {time.ctime(st.st_mtime)}\"\n    except Exception as e:\n        return f\"{Path(p).name}  |  <stat error: {e}>\"\n\np2_dir = latest_phase2(WORKDIR)\nassert p2_dir, \"❌ No Phase-2 run directory found.\"\n\nprint(f\"🔎 Phase-2 run: {p2_dir}\")\n\ndone, best_epoch, best_col, best_val = epochs_from_results_csv(p2_dir)\nprint(f\"📈 Epochs completed (from results.csv): {done}\")\nif best_epoch is not None:\n    print(f\"🏆 Best epoch (by {best_col}): {best_epoch}  (value={best_val:.4f})\")\n\nep_files, best, last = list_weights(p2_dir)\nprint(f\"\\n💾 Saved epoch checkpoints: {len(ep_files)} file(s)\")\nif ep_files:\n    print(\"  First 5:\", [f\"epoch{n}\" for n,_ in ep_files[:5]])\n    print(\"  Last  5:\", [f\"epoch{n}\" for n,_ in ep_files[-5:]])\n\nprint(\"\\nBest/Last:\")\nprint(\"  best.pt:\", file_info(best) if best else \"missing\")\nprint(\"  last.pt:\", file_info(last) if last else \"missing\")\n\nif ep_files:\n    latest_epoch, latest_path = ep_files[-1]\n    print(\"  latest epoch*.pt:\", file_info(latest_path))\nelse:\n    latest_epoch, latest_path = None, None\n\n# Optional: try to load a few weights to ensure they are usable\nif CHECK_LOAD:\n    try:\n        from ultralytics import YOLO\n        for tag, p in [(\"best\", best), (\"last\", last), (f\"epoch{latest_epoch}\", latest_path)]:\n            if p and os.path.exists(p):\n                try:\n                    _ = YOLO(p)  # just construct; no inference\n                    print(f\"✅ Load OK → {tag}: {p}\")\n                except Exception as e:\n                    print(f\"❌ Load FAILED → {tag}: {p}  |  {e}\")\n    except Exception as e:\n        print(\"⚠️ Skipped load checks:\", e)\n\nprint(\"\\nDone.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T20:40:01.158595Z","iopub.execute_input":"2025-08-12T20:40:01.159035Z","iopub.status.idle":"2025-08-12T20:40:01.478705Z","shell.execute_reply.started":"2025-08-12T20:40:01.159011Z","shell.execute_reply":"2025-08-12T20:40:01.477869Z"}},"outputs":[{"name":"stdout","text":"🔎 Phase-2 run: /kaggle/working/vehdet/y8_phase2_896\n📈 Epochs completed (from results.csv): 80\n🏆 Best epoch (by metrics/mAP50-95(B)): 59  (value=0.5462)\n\n💾 Saved epoch checkpoints: 79 file(s)\n  First 5: ['epoch0', 'epoch1', 'epoch2', 'epoch3', 'epoch4']\n  Last  5: ['epoch74', 'epoch75', 'epoch76', 'epoch77', 'epoch78']\n\nBest/Last:\n  best.pt: best.pt  |  52.0 MB  |  Tue Aug 12 19:44:24 2025\n  last.pt: last.pt  |  52.0 MB  |  Tue Aug 12 19:44:24 2025\n  latest epoch*.pt: epoch78.pt  |  155.7 MB  |  Tue Aug 12 19:44:24 2025\n✅ Load OK → best: /kaggle/working/vehdet/y8_phase2_896/weights/best.pt\n✅ Load OK → last: /kaggle/working/vehdet/y8_phase2_896/weights/last.pt\n✅ Load OK → epoch78: /kaggle/working/vehdet/y8_phase2_896/weights/epoch78.pt\n\nDone.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# ================== EXPORT PHASE-2 ARTIFACTS (PERSIST THEM!) ==================\nimport os, glob, time, zipfile, shutil\nfrom pathlib import Path\nimport pandas as pd\n\nWORKDIR = \"/kaggle/working/vehdet\"\n\ndef latest_phase2(root):\n    runs = glob.glob(os.path.join(root, \"y8_phase2_*\"))\n    return sorted(runs, key=os.path.getmtime, reverse=True)[0] if runs else None\n\ndef pick_best_epoch(results_csv):\n    df = pd.read_csv(results_csv)\n    for col in [\"metrics/mAP50-95(B)\", \"metrics/mAP50-95\", \"fitness\", \"metrics/mAP50(B)\", \"metrics/mAP50\"]:\n        if col in df.columns:\n            idx = int(df[col].idxmax())\n            return int(df.loc[idx, \"epoch\"]), col, float(df.loc[idx, col])\n    # fallback\n    return int(df[\"epoch\"].max()), \"epoch(max)\", float(\"nan\")\n\np2_dir = latest_phase2(WORKDIR)\nassert p2_dir, \"No Phase-2 run found.\"\n\nwdir = os.path.join(p2_dir, \"weights\")\nbest = os.path.join(wdir, \"best.pt\")\nlast = os.path.join(wdir, \"last.pt\")\nres_csv = os.path.join(p2_dir, \"results.csv\")\nassert os.path.exists(res_csv), f\"Missing results.csv in {p2_dir}\"\n\nbest_epoch, col, val = pick_best_epoch(res_csv)\nepN = os.path.join(wdir, f\"epoch{best_epoch}.pt\")\nprint(f\"Best epoch = {best_epoch} by {col} (value={val:.4f})\")\n\nexport = os.path.join(WORKDIR, \"export_phase2\")\nos.makedirs(export, exist_ok=True)\n\ndef keep(src, newname=None):\n    if src and os.path.exists(src):\n        dst = os.path.join(export, newname or Path(src).name)\n        shutil.copy2(src, dst)\n        print(\"✓\", Path(dst).name)\n        return dst\n\nkept = []\nkept += [keep(best, \"phase2_best.pt\")]\nkept += [keep(last, \"phase2_last.pt\")]\nkept += [keep(epN, f\"phase2_epoch{best_epoch}.pt\")]\nkept += [keep(res_csv, \"phase2_results.csv\")]\nfor nm in [\"args.yaml\",\"args.json\",\"hyp.yaml\"]:\n    kept += [keep(os.path.join(p2_dir, nm), f\"phase2_{nm}\")]\n\n# also keep data.yaml for evaluation/inference consistency\nkept += [keep(os.path.join(WORKDIR, \"data.yaml\"), \"data.yaml\")]\n\n# zip everything so you can download or save as output\nzip_path = os.path.join(WORKDIR, f\"phase2_export_{int(time.time())}.zip\")\nwith zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n    for p in filter(None, kept):\n        z.write(p, arcname=Path(p).name)\n\nprint(\"\\nExport folder:\", export)\nprint(\"ZIP archive  :\", zip_path)\nprint(\"→ Now either: (A) Save Version with 'Save output' checked, or (B) download the ZIP.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T20:44:27.529876Z","iopub.execute_input":"2025-08-12T20:44:27.530645Z","iopub.status.idle":"2025-08-12T20:44:43.090053Z","shell.execute_reply.started":"2025-08-12T20:44:27.530614Z","shell.execute_reply":"2025-08-12T20:44:43.089216Z"}},"outputs":[{"name":"stdout","text":"Best epoch = 59 by metrics/mAP50-95(B) (value=0.5462)\n✓ phase2_best.pt\n✓ phase2_last.pt\n✓ phase2_epoch59.pt\n✓ phase2_results.csv\n✓ phase2_args.yaml\n✓ data.yaml\n\nExport folder: /kaggle/working/vehdet/export_phase2\nZIP archive  : /kaggle/working/vehdet/phase2_export_1755031467.zip\n→ Now either: (A) Save Version with 'Save output' checked, or (B) download the ZIP.\n","output_type":"stream"}],"execution_count":52}]}